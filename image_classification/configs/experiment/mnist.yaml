# @package _global_

experiment_name: mnist

num_classes: &num_classes 10
# NOTE: this entry is assumed to be present
metric_to_optimize: &metric_to_optimize "val_f1"

module:
  network:
    _target_: image_classification.network.MNISTNet
  loss:
    _target_: image_classification.losses.FocalLoss
    gamma: 2
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.01
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.ReduceLROnPlateau
  training_metrics:
    train_f1:
      _target_: torchmetrics.F1
      num_classes: *num_classes
  validation_metrics:
    val_f1:
      _target_: torchmetrics.F1
      num_classes: *num_classes
    val_cm:
      _target_: image_classification.metrics.MetricsWrapper
      log: false
      metric:
        _target_: torchmetrics.ConfusionMatrix
        num_classes: *num_classes
        normalize: "true"
  monitor: "val_loss"
  hp_metric: *metric_to_optimize

  visualization:
    - _target_: image_classification.visualization.Figure
      stage: on_validation_epoch_end
      identifier: confusion_matrix
      plotter:
        _target_: image_classification.visualization.ConfusionMatrixPlotter
      targets: {val_cm: confusion_matrix}
      input_ax: true
      figure_kwargs:
        figsize: [8, 8]

data:
  _target_: image_classification.data.MNISTDataModule
  data_dir: ${data_dir}
  batch_size: 32
  download: true
