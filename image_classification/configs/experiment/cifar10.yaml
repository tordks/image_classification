# @package _global_

# This example is taken from the cifar10 baseline in the pytorch lightning documentation:
# https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/cifar10-baseline.html

experiment_name: cifar10
experiment_description: basline cifar10 using pl_bolts example

num_classes: &num_classes 10
metric_to_optimize: &metric_to_optimize "val_f1"

module:
  network:
    _target_: image_classification.network.create_cifar10_resnet
  loss:
    _target_: torch.nn.CrossEntropyLoss

  batch_mapping:
    0: feature
    1: label

  optimizer:
    _target_: torch.optim.SGD
    lr: 0.01
    momentum: 0.9
    weight_decay: 0.00005

  lr_scheduler:
    scheduler:
      _target_: torch.optim.lr_scheduler.OneCycleLR
      max_lr: 0.1
      epochs: ${trainer.max_epochs}
      steps_per_epoch:
        _target_: image_classification.utils.evaluate
        expression: "45000 // ${data.batch_size}"
    interval: "epoch"
    monitor: "val_loss"

  training_metrics:
    train_f1:
      _target_: torchmetrics.F1
      num_classes: *num_classes
  validation_metrics:
    val_f1:
      _target_: torchmetrics.F1
      num_classes: *num_classes
    val_acc:
      _target_: torchmetrics.Accuracy
      num_classes: *num_classes
    val_cm:
      _target_: image_classification.metrics.MetricsWrapper
      log: false
      metric:
        _target_: torchmetrics.ConfusionMatrix
        num_classes: *num_classes
        normalize: "true"

  transforms:
    - _target_: image_classification.transforms.Transform
      identifier: argmax
      stage: training_step_after_predict
      every_n: 256
      targets: "prediction"
      transform:
        _target_: torch.argmax
        _partial_: true
        dim: 1

  visualization:
    - _target_: image_classification.visualization.Subplots
      identifier: "Train images"
      stage: training_step_after_predict
      every_n: 256
      batch_idx: 0
      title: "Feature l:{label} p:{prediction_argmax}"
      nrows: 1
      ncols: 1
      subplots_kwargs:
        figsize: [8, 8]

      plotters:
        - _target_: image_classification.visualization.Plotter
          plotter:
            _target_: matplotlib.pyplot.imshow
            _partial_: true
          targets: { feature: 0 }
          rearrange_pattern: "C H W -> H W C"

    - _target_: image_classification.visualization.Subplots
      identifier: "confusion matrix"
      stage: on_validation_epoch_end
      every_n: 1
      nrows: 1
      ncols: 1
      subplots_kwargs:
        figsize: [8, 8]
      plotters:
        - _target_: image_classification.visualization.Plotter
          plotter:
            _target_: image_classification.visualization.ConfusionMatrixPlotter
          targets: { val_cm: confusion_matrix }

  hp_metric: *metric_to_optimize

data:
  _target_: pl_bolts.datamodules.CIFAR10DataModule
  data_dir: ${data_dir}
  train_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.RandomCrop
        _args_: [32]
        padding: 4
      - _target_: torchvision.transforms.RandomHorizontalFlip
      - _target_: torchvision.transforms.ToTensor
      - _target_: pl_bolts.transforms.dataset_normalizations.cifar10_normalization
  test_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.ToTensor
      - _target_: pl_bolts.transforms.dataset_normalizations.cifar10_normalization
  val_transforms:
    _target_: torchvision.transforms.Compose
    transforms:
      - _target_: torchvision.transforms.ToTensor
      - _target_: pl_bolts.transforms.dataset_normalizations.cifar10_normalization
  batch_size: 256
  num_workers: 20
